{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data\\train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist=input_data.read_data_sets(\"/tmp/data\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample= mnist.train.images[2].reshape(28,28)\n",
    "sample= mnist.train.images[2034].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b0146a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1af9e9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample,cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to define the parameters\n",
    "# learning rate\n",
    "# batch size\n",
    "learning_rate=0.001  # how quickly we are going to adjust the cost function\n",
    "training_epochs=15 #how many training cycles go through\n",
    "batch_size=100  # the size of the batch in the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes=10  # number of classes of the target variables\n",
    "n_samples=mnist.train.num_examples  # number of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input=784 # the input dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden_1=256\n",
    "n_hidden_2=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x,weights,biases):\n",
    "    \"\"\"\n",
    "    x: placeholder for data input\n",
    "    weights: dict of weights\n",
    "    biases: dict of bias values\n",
    "    \"\"\"\n",
    "    \n",
    "    # first hidden layer with RELU activation\n",
    "    # X*W+B\n",
    "    layer_1=tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    # RELU -> f(x)=max(0,x) -> max(x, X*W+B)\n",
    "    layer_1=tf.nn.relu(layer_1)\n",
    "    \n",
    "    #second hidden layer\n",
    "    layer_2=tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
    "    layer_2=tf.nn.relu(layer_2)\n",
    "    \n",
    "    # last output layer: linear out layer\n",
    "    out_layer=tf.matmul(layer_2,weights['out'])+biases['out']\n",
    "\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights={\n",
    "    'h1':tf.Variable(tf.random_normal([n_input,n_hidden_1])), # Outputs random values from a normal distribution, arg is shape\n",
    "    'h2':tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2,n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h1': <tensorflow.python.ops.variables.Variable at 0x23e16488c88>,\n",
       " 'h2': <tensorflow.python.ops.variables.Variable at 0x23e162d6fd0>,\n",
       " 'out': <tensorflow.python.ops.variables.Variable at 0x23e162e0358>}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases={\n",
    "    'b1':tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b1': <tf.Variable 'Variable_3:0' shape=(256,) dtype=float32_ref>,\n",
       " 'b2': <tf.Variable 'Variable_4:0' shape=(256,) dtype=float32_ref>,\n",
       " 'out': <tf.Variable 'Variable_5:0' shape=(10,) dtype=float32_ref>}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# place holder for x and y\n",
    "x=tf.placeholder('float',[None,n_input])\n",
    "y=tf.placeholder('float',[None,n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred=multilayer_perceptron(x,weights,biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred,y))\n",
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer=tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t=mnist.train.next_batch(10) # the number in next_batch means how many rows (predictive y) we are going to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(t))\n",
    "print(len(t[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t=mnist.train.next_batch(10)\n",
    "Xsamp,ysamp=t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 784)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xsamp.shape  # (1,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.33333334, 0.9921569 , 0.32941177,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.8235295 , 0.98823535, 0.32941177, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.34901962, 0.96470594, 0.98823535,\n",
       "       0.32941177, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.5019608 , 0.98823535, 0.98823535, 0.32941177, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.9921569 , 0.98823535,\n",
       "       0.98823535, 0.32941177, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 1.        , 0.9921569 , 0.9921569 , 0.32941177,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.9921569 ,\n",
       "       0.98823535, 0.91372555, 0.21960786, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.43529415, 0.9921569 , 0.98823535, 0.76470596,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.07450981, 0.8431373 ,\n",
       "       0.9921569 , 0.98823535, 0.40000004, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.41960788, 0.98823535, 0.9921569 , 0.8000001 ,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.6627451 ,\n",
       "       0.9921569 , 1.        , 0.65882355, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.6627451 , 0.98823535, 0.9921569 ,\n",
       "       0.16470589, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.6627451 , 0.98823535, 0.9921569 , 0.10588236, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.21176472, 0.87843144, 0.98823535,\n",
       "       0.69803923, 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.7725491 , 0.98823535, 0.98823535, 0.24705884, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.14901961, 0.8705883 , 0.9921569 ,\n",
       "       0.9921569 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.33333334, 0.98823535, 0.98823535, 0.8000001 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.33333334, 0.98823535,\n",
       "       0.98823535, 0.43921572, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.33333334, 0.98823535, 0.98823535, 0.43921572,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.33333334,\n",
       "       0.98823535, 0.6156863 , 0.19607845, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xsamp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23e16d9f908>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23e16e455f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Xsamp[0~9] for batch size 10\n",
    "plt.imshow(Xsamp[9].reshape(28,28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.random_normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ysamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()  # need to initialize the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost167.8200\n",
      "Epoch: 2 cost40.6655\n",
      "Epoch: 3 cost25.3037\n",
      "Epoch: 4 cost17.4549\n",
      "Epoch: 5 cost12.7591\n",
      "Epoch: 6 cost9.4524\n",
      "Epoch: 7 cost7.0783\n",
      "Epoch: 8 cost5.2375\n",
      "Epoch: 9 cost3.9145\n",
      "Epoch: 10 cost2.8185\n",
      "Epoch: 11 cost2.2186\n",
      "Epoch: 12 cost1.6552\n",
      "Epoch: 13 cost1.2414\n",
      "Epoch: 14 cost0.9603\n",
      "Epoch: 15 cost0.7079\n",
      "Model has completed 15 Epochs of training\n"
     ]
    }
   ],
   "source": [
    "# 15 loops\n",
    "for epoch in range(training_epochs):\n",
    "    \n",
    "    #Cost\n",
    "    avg_cost=0.0  # this is the initial cost, and will add the cost onto this value\n",
    "    \n",
    "    total_batch=int(n_samples/batch_size)  # 550, this is iteration number\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        _,c=sess.run([optimizer,cost],feed_dict={x:batch_x,y:batch_y}) # use _ for unused values in tuple unpacking\n",
    "        avg_cost+=c/total_batch\n",
    "        \n",
    "    print('Epoch: {} cost{:.4f}'.format(epoch+1,avg_cost))\n",
    "    \n",
    "print('Model has completed {} Epochs of training'.format(training_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions=tf.equal(tf.argmax(pred,1),tf.argmax(y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Size:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.size(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice:0\", shape=(), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions[0])  # type is bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_predictions=tf.cast(correct_predictions,'float')  # need to convert it to numeric in order to take mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(correct_predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy=tf.reduce_mean(correct_predictions)  # take the mean of the tensor, same as numpy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.32941177, 0.7254902 , 0.62352943,\n",
       "       0.5921569 , 0.23529413, 0.14117648, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.8705883 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9450981 , 0.77647066, 0.77647066, 0.77647066, 0.77647066,\n",
       "       0.77647066, 0.77647066, 0.77647066, 0.77647066, 0.6666667 ,\n",
       "       0.20392159, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.2627451 , 0.44705886,\n",
       "       0.28235295, 0.44705886, 0.6392157 , 0.89019614, 0.9960785 ,\n",
       "       0.882353  , 0.9960785 , 0.9960785 , 0.9960785 , 0.9803922 ,\n",
       "       0.8980393 , 0.9960785 , 0.9960785 , 0.54901963, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "       0.2627451 , 0.2627451 , 0.23137257, 0.08235294, 0.92549026,\n",
       "       0.9960785 , 0.4156863 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.3254902 , 0.9921569 , 0.8196079 , 0.07058824,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.08627451, 0.91372555,\n",
       "       1.        , 0.3254902 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.5058824 , 0.9960785 , 0.9333334 , 0.17254902,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.23137257, 0.97647065,\n",
       "       0.9960785 , 0.24313727, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.52156866, 0.9960785 , 0.73333335, 0.01960784,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03529412, 0.80392164,\n",
       "       0.9725491 , 0.227451  , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.49411768, 0.9960785 , 0.7137255 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.29411766, 0.9843138 ,\n",
       "       0.94117653, 0.22352943, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.07450981, 0.86666673, 0.9960785 , 0.6509804 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.7960785 , 0.9960785 ,\n",
       "       0.8588236 , 0.13725491, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.14901961, 0.9960785 , 0.9960785 , 0.3019608 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.12156864, 0.87843144, 0.9960785 ,\n",
       "       0.45098042, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.52156866, 0.9960785 , 0.9960785 , 0.20392159, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.2392157 , 0.9490197 , 0.9960785 ,\n",
       "       0.9960785 , 0.20392159, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.47450984, 0.9960785 , 0.9960785 , 0.8588236 , 0.15686275,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.47450984, 0.9960785 ,\n",
       "       0.8117648 , 0.07058824, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mnist.test.images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it called accuracy function which contains correct predictions, and it includes pred and y. pred has x (our features), y is our labels.\n",
    "In this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9459"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.eval({x:mnist.test.images,y:mnist.test.labels})  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
